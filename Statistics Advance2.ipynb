{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f7c94442-92e9-43ed-8f35-91a042bc8750",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0a86c-addd-4b41-b783-94a1f46f9b20",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are two concepts used in probability theory and statistics to describe the probability distribution of a random variable. They are used for different types of random variables: PMF for discrete random variables and PDF for continuous random variables.\n",
    "\n",
    "1. **Probability Mass Function (PMF):**\n",
    "   - The PMF is used for discrete random variables, which have countable outcomes.\n",
    "   - It provides the probability that a random variable takes on a specific value.\n",
    "   - The PMF assigns probabilities to individual data points.\n",
    "   - The sum of probabilities for all possible values of the random variable equals 1.\n",
    "   - It is typically represented as P(X = x), where X is the random variable, and x is a specific value.\n",
    "\n",
    "**Example of PMF:**\n",
    "Consider the outcome of rolling a fair six-sided die. The PMF of this discrete random variable is:\n",
    "- P(X = 1) = 1/6\n",
    "- P(X = 2) = 1/6\n",
    "- P(X = 3) = 1/6\n",
    "- P(X = 4) = 1/6\n",
    "- P(X = 5) = 1/6\n",
    "- P(X = 6) = 1/6\n",
    "\n",
    "2. **Probability Density Function (PDF):**\n",
    "   - The PDF is used for continuous random variables, which have an infinite number of possible outcomes within an interval.\n",
    "   - It provides the probability density at a particular point or within a range.\n",
    "   - The PDF assigns a density (not a probability) to each point along the real number line.\n",
    "   - The total area under the PDF curve over a given interval represents the probability of the random variable falling within that interval.\n",
    "\n",
    "**Example of PDF:**\n",
    "Consider the height of adult males. This is a continuous random variable with a PDF that might resemble a bell-shaped curve, such as the normal distribution. The PDF gives the probability density of a man's height at any specific height value within the possible range of heights. For example, the PDF might tell you that the density of men with a height of exactly 175 cm is higher than at 180 cm. However, it doesn't give the probability that a randomly selected man will have an exact height of 175 cm, as the probability at a single point in a continuous distribution is technically zero.\n",
    "\n",
    "In summary, PMF and PDF are used to describe the distributions of discrete and continuous random variables, respectively. PMF provides probabilities for specific outcomes, while PDF provides densities over ranges of values."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a778fb45-bb35-427e-b1f6-5c3e47c71774",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00988b5-ae64-4a5f-bef8-a5cb2ba1d1c3",
   "metadata": {},
   "source": [
    "**Cumulative Density Function (CDF):**\n",
    "A Cumulative Density Function (CDF) is a concept used in probability theory and statistics to describe the probability distribution of a random variable. The CDF of a random variable X, denoted as F(x), provides the probability that X takes on a value less than or equal to a given value x. In other words, it accumulates the probabilities associated with values up to and including x.\n",
    "\n",
    "**Mathematically, for a random variable X:**\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "The CDF is used to answer questions like \"What is the probability that X is less than or equal to a specific value x?\"\n",
    "\n",
    "**Example of CDF:**\n",
    "Consider a random variable X representing the outcome of rolling a fair six-sided die. The CDF for X would be as follows:\n",
    "\n",
    "- F(1) = P(X ≤ 1) = 1/6 (because there's one way to get a 1: rolling a 1)\n",
    "- F(2) = P(X ≤ 2) = 2/6 (two ways to get 1 or 2)\n",
    "- F(3) = P(X ≤ 3) = 3/6 (three ways to get 1, 2, or 3)\n",
    "- F(4) = P(X ≤ 4) = 4/6\n",
    "- F(5) = P(X ≤ 5) = 5/6\n",
    "- F(6) = P(X ≤ 6) = 6/6 = 1 (since all values are less than or equal to 6)\n",
    "\n",
    "The CDF provides a way to understand the cumulative probability distribution of the random variable. It's a valuable tool for a variety of purposes:\n",
    "\n",
    "1. **Evaluating probabilities**: CDFs are used to find the probability that a random variable falls within a certain range.\n",
    "\n",
    "2. **Quantiles**: They help identify percentiles and quantiles, such as the median (50th percentile).\n",
    "\n",
    "3. **Comparing distributions**: CDFs are useful for comparing the distributions of different random variables or for assessing the goodness-of-fit of a theoretical distribution to empirical data.\n",
    "\n",
    "4. **Simulation and modeling**: In statistical modeling and simulations, CDFs are used to generate random samples from a given distribution.\n",
    "\n",
    "In summary, the Cumulative Density Function is a crucial concept in statistics for understanding and working with the probabilities associated with random variables, making it a fundamental tool in data analysis, research, and decision-making."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7815de53-8df8-4474-b212-f0bbe808c4c3",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a171083-990e-4515-8371-5404b6c0114b",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a versatile probability distribution that is commonly used to model a wide range of natural phenomena and statistical processes. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1. **Biological Measurements:** Many biological characteristics, such as human height, weight, and blood pressure, approximate a normal distribution. For example, when measuring the heights of a large random sample of adults, the distribution of heights tends to follow a bell-shaped curve.\n",
    "\n",
    "2. **Psychometric Testing:** Test scores from standardized exams, IQ scores, and psychological measurements often follow a normal distribution. This makes the normal distribution useful for understanding the performance of a population on these tests.\n",
    "\n",
    "3. **Economic and Financial Data:** In finance, returns on investments, stock prices, and other economic variables often exhibit approximately normal distributions. This is a key assumption in various financial models.\n",
    "\n",
    "4. **Measurement Errors:** Measurement errors in scientific experiments, such as the errors in laboratory equipment or observational instruments, are often normally distributed. This makes it possible to model and correct for these errors statistically.\n",
    "\n",
    "5. **Quality Control:** In manufacturing processes, product dimensions and quality characteristics are often modeled using the normal distribution. Deviations from specified values are monitored and controlled using statistical process control.\n",
    "\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). These parameters have a significant impact on the shape of the distribution:\n",
    "\n",
    "1. **Mean (μ):** The mean determines the center or peak of the distribution. It's also the median and mode of the distribution. Shifting the mean to the right or left will shift the entire distribution accordingly.\n",
    "\n",
    "2. **Standard Deviation (σ):** The standard deviation controls the spread or dispersion of the distribution. A smaller standard deviation results in a narrower, more concentrated distribution, while a larger standard deviation produces a broader, more spread-out distribution. \n",
    "\n",
    "The normal distribution is symmetric around the mean. When the standard deviation is small, the distribution is tall and narrow, indicating low variability. Conversely, when the standard deviation is large, the distribution is shorter and wider, suggesting higher variability. The empirical rule, also known as the 68-95-99.7 rule, is often used to describe the characteristics of the normal distribution in terms of standard deviations from the mean:\n",
    "\n",
    "- About 68% of the data falls within one standard deviation of the mean.\n",
    "- About 95% falls within two standard deviations.\n",
    "- About 99.7% falls within three standard deviations.\n",
    "\n",
    "These characteristics make the normal distribution a valuable tool in statistics and data analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f9ea605-0208-45c0-9e35-3399b0053acd",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b97a7-8595-4666-8a23-920a849d749e",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is of paramount importance in statistics, data analysis, and various fields due to several reasons:\n",
    "\n",
    "1. **Common Natural Phenomena:** Many real-world processes and characteristics approximate a normal distribution. This makes it a fundamental tool for understanding and modeling various phenomena.\n",
    "\n",
    "2. **Statistical Inference:** The normal distribution is the basis for many statistical methods and hypothesis testing. It simplifies calculations and provides a solid foundation for making inferences about populations.\n",
    "\n",
    "3. **Central Limit Theorem:** The Central Limit Theorem states that the distribution of the sample means from any population approaches a normal distribution as the sample size increases. This theorem is crucial for inferential statistics, as it allows us to make inferences about a population based on sample data.\n",
    "\n",
    "4. **Data Analysis:** It is used for data analysis, visualization, and making predictions. Many statistical tools and software are designed with the assumption that data follows a normal distribution.\n",
    "\n",
    "5. **Quality Control:** In manufacturing, the normal distribution is used for quality control to monitor and maintain the consistency and quality of products.\n",
    "\n",
    "6. **Finance:** The normal distribution is widely used in finance for modeling asset returns, risk assessment, and portfolio optimization.\n",
    "\n",
    "7. **Biostatistics:** It is used to model biological measurements like height, weight, and blood pressure, making it important in medical research and healthcare.\n",
    "\n",
    "8. **Psychology and Social Sciences:** In psychometrics, IQ scores, personality traits, and many other psychological and sociological variables are assumed to be normally distributed.\n",
    "\n",
    "Examples of real-life situations where the normal distribution is observed include:\n",
    "\n",
    "1. **Human Height:** The distribution of adult human heights approximates a normal distribution. Most people fall within the average height range, and fewer individuals are significantly taller or shorter.\n",
    "\n",
    "2. **IQ Scores:** Standardized IQ scores are designed to follow a normal distribution with a mean of 100 and a standard deviation of 15. This allows for a comparison of cognitive abilities across a population.\n",
    "\n",
    "3. **Stock Prices:** Daily returns of many stocks follow a nearly normal distribution. It is used in financial models to assess risk and analyze stock market behavior.\n",
    "\n",
    "4. **Measurement Errors:** Measurement errors in scientific experiments often approximate a normal distribution. Researchers use this understanding to account for and correct these errors.\n",
    "\n",
    "5. **Test Scores:** Scores on standardized tests, such as the SAT or GRE, are often assumed to follow a normal distribution. This allows for the interpretation of individual scores in the context of the overall test-taking population.\n",
    "\n",
    "6. **Quality Control:** In manufacturing, dimensions and characteristics of products often follow a normal distribution. Quality control processes use the normal distribution to monitor product quality.\n",
    "\n",
    "The normal distribution's importance lies in its widespread applicability across various disciplines, simplifying statistical analysis and providing a foundation for many statistical methods and models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49348c13-0263-49ee-9ca2-bfcc66121700",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407054b-8ed3-43bb-b359-27e545200438",
   "metadata": {},
   "source": [
    "**Bernoulli Distribution:**\n",
    "The Bernoulli distribution is a discrete probability distribution representing a random variable that can take one of two possible outcomes, often labeled as \"success\" and \"failure.\" It is characterized by a single parameter, denoted as \"p,\" which represents the probability of success (and, by extension, \"1 - p\" is the probability of failure).\n",
    "\n",
    "The probability mass function (PMF) for a Bernoulli distribution is given by:\n",
    "P(X = 1) = p (probability of success)\n",
    "P(X = 0) = 1 - p (probability of failure)\n",
    "\n",
    "**Example of Bernoulli Distribution:**\n",
    "A classic example is flipping a fair coin, where you define \"heads\" as success and \"tails\" as failure. If the probability of getting heads (success) is p = 0.5 (since it's a fair coin), then the Bernoulli distribution models the outcome of a single coin flip, where X can be 1 (heads) with probability 0.5 and 0 (tails) with probability 0.5.\n",
    "\n",
    "**Difference Between Bernoulli and Binomial Distributions:**\n",
    "The key differences between the Bernoulli distribution and the Binomial distribution are as follows:\n",
    "\n",
    "1. **Number of Trials:**\n",
    "   - Bernoulli Distribution: Models a single trial or experiment with only two possible outcomes (success or failure).\n",
    "   - Binomial Distribution: Models a fixed number (n) of independent and identical trials, each following a Bernoulli distribution.\n",
    "\n",
    "2. **Parameters:**\n",
    "   - Bernoulli Distribution: It has one parameter, \"p,\" representing the probability of success in a single trial.\n",
    "   - Binomial Distribution: It has two parameters, \"n\" (the number of trials) and \"p\" (the probability of success in each trial).\n",
    "\n",
    "3. **Random Variable:**\n",
    "   - Bernoulli Distribution: The random variable X in a Bernoulli distribution takes on values 0 or 1 (failure or success) for a single trial.\n",
    "   - Binomial Distribution: The random variable X in a Binomial distribution represents the number of successes in 'n' trials and can take values from 0 to 'n'.\n",
    "\n",
    "4. **Probability Mass Function (PMF):**\n",
    "   - Bernoulli Distribution: The PMF involves only two probabilities, one for success (p) and one for failure (1 - p).\n",
    "   - Binomial Distribution: The PMF provides probabilities for different counts of successes in 'n' trials, allowing for a range of possible values.\n",
    "\n",
    "In summary, the Bernoulli distribution models a single trial with two possible outcomes, while the Binomial distribution extends this to multiple trials, providing the probability distribution for the number of successes in a fixed number of trials. The Binomial distribution is a generalization of the Bernoulli distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "10ad91e8-a648-4a5e-9c4d-0f759a3955fa",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddb608-9255-483d-a3eb-106c7a64f1fc",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation from a normally distributed dataset will be greater than 60, you can use the Z-score formula and standard normal distribution tables. Here are the steps to calculate it:\n",
    "\n",
    "1. Calculate the Z-score:\n",
    "   The Z-score (or standard score) measures how many standard deviations an observation is from the mean. It is calculated using the formula:\n",
    "   \n",
    "   Z = (X - μ) / σ\n",
    "\n",
    "   Where:\n",
    "   - X is the value you want to find the probability for (in this case, 60).\n",
    "   - μ is the mean of the dataset (given as 50).\n",
    "   - σ is the standard deviation of the dataset (given as 10).\n",
    "\n",
    "   Calculate Z:\n",
    "\n",
    "   Z = (60 - 50) / 10 = 1\n",
    "\n",
    "2. Find the probability using the Z-score:\n",
    "   You can now find the probability associated with a Z-score of 1 using a standard normal distribution table or calculator. The probability is the area under the standard normal distribution curve to the right of the Z-score.\n",
    "\n",
    "   P(Z > 1) can be found using a standard normal distribution table, which typically provides the probability associated with the Z-score. \n",
    "\n",
    "   From the table, you can find P(Z > 1) is approximately 0.1587.\n",
    "\n",
    "So, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1fd3c23-a149-411e-91d2-01e86787f3b4",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3b6f5-a8db-4e30-a581-e5b9c18918be",
   "metadata": {},
   "source": [
    "**Uniform Distribution:**\n",
    "\n",
    "The uniform distribution is a continuous probability distribution where all values within a given interval are equally likely to occur. It is characterized by a constant probability density function (PDF) over the entire range of possible values. In other words, in a uniform distribution, every outcome has the same likelihood of occurring.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "The PDF of a uniform distribution is defined as follows:\n",
    "\n",
    "f(x) = 1 / (b - a), for a ≤ x ≤ b\n",
    "f(x) = 0, elsewhere\n",
    "\n",
    "Where:\n",
    "- f(x) is the PDF.\n",
    "- a and b are the endpoints of the interval.\n",
    "\n",
    "**Example of Uniform Distribution:**\n",
    "Consider a fair six-sided die. When you roll this die, there are six possible outcomes (1, 2, 3, 4, 5, 6), and each outcome is equally likely. This situation follows a discrete uniform distribution. In this case, the probability of each outcome is 1/6 because there are six equally likely outcomes.\n",
    "\n",
    "For a continuous uniform distribution, think of a random variable that can take any real number between 0 and 1 with equal likelihood. In this case, the PDF is constant within the interval [0, 1] and is zero outside that interval. The PDF for this example is:\n",
    "\n",
    "f(x) = 1, for 0 ≤ x ≤ 1\n",
    "f(x) = 0, elsewhere\n",
    "\n",
    "In this continuous uniform distribution, any value between 0 and 1 is equally likely to be selected, and the area under the PDF curve within the interval [0, 1] is equal to 1, indicating that the probabilities sum to 1.\n",
    "\n",
    "The uniform distribution is often used in situations where each value within a range is equally likely, such as selecting a random point in a given interval or modeling situations where randomness is attributed to a lack of knowledge about the specific value."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49d0105e-2bc3-4e6b-8d10-2695aba49e7b",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1f34a-b656-4baf-b936-e285c931be1c",
   "metadata": {},
   "source": [
    "**Z-Score (Standard Score):**\n",
    "The z-score, also known as the standard score, is a measure of how many standard deviations a particular data point is away from the mean (average) of a dataset. It is a standardized measure used in statistics to compare and analyze data across different distributions and populations.\n",
    "\n",
    "The formula to calculate the z-score of an individual data point, X, in a dataset with mean (μ) and standard deviation (σ), is:\n",
    "\n",
    "\\[Z = \\frac{X - \\mu}{\\sigma}\\]\n",
    "\n",
    "Where:\n",
    "- Z is the z-score.\n",
    "- X is the data point.\n",
    "- μ is the mean of the dataset.\n",
    "- σ is the standard deviation of the dataset.\n",
    "\n",
    "**Importance of Z-Score:**\n",
    "\n",
    "The z-score is important for several reasons:\n",
    "\n",
    "1. **Standardization:** Z-scores allow for the standardization of data, making it possible to compare data from different datasets or populations with varying means and standard deviations. This standardization simplifies statistical analysis and interpretation.\n",
    "\n",
    "2. **Identifying Outliers:** Z-scores help in identifying outliers or extreme values. Data points with high absolute z-scores (far from the mean) may indicate unusual or rare occurrences in a dataset.\n",
    "\n",
    "3. **Normal Distribution Analysis:** In a standard normal distribution (a normal distribution with a mean of 0 and a standard deviation of 1), the z-score directly provides the probability associated with a given data point, making it valuable in probability calculations.\n",
    "\n",
    "4. **Hypothesis Testing:** Z-scores are used in hypothesis testing to determine the significance of observed differences between sample data and population parameters. They help assess whether an observed effect is statistically significant.\n",
    "\n",
    "5. **Data Transformation:** Z-scores are used to transform data into a standard normal distribution, which simplifies various statistical tests and comparisons.\n",
    "\n",
    "6. **Grading and Assessment:** Z-scores are commonly used in educational settings to compare a student's test score to the mean and standard deviation of the scores of all students. This allows educators to assess individual performance relative to the entire class.\n",
    "\n",
    "7. **Quality Control:** In quality control and manufacturing, z-scores are used to monitor and maintain product quality. They help determine if a product's dimensions or characteristics are within an acceptable range.\n",
    "\n",
    "8. **Finance and Risk Assessment:** Z-scores are applied in finance to assess the creditworthiness of individuals and companies, particularly in credit scoring models.\n",
    "\n",
    "In summary, the z-score plays a crucial role in standardizing data, enabling comparisons, identifying outliers, and making data analysis and interpretation more efficient and meaningful in various fields, including statistics, education, quality control, and finance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "53b22551-98c9-4c9b-952a-3f0a670bf8aa",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb1536-d72f-4a8f-b716-49a259ae8fd4",
   "metadata": {},
   "source": [
    "**Central Limit Theorem (CLT):**\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics. It states that, regardless of the shape of the original population distribution, the sampling distribution of the sample mean will become approximately normally distributed as the sample size increases, especially for sufficiently large sample sizes.\n",
    "\n",
    "In essence, the CLT has three key principles:\n",
    "\n",
    "1. For a random sample taken from any population (with finite variance), the distribution of the sample means will tend to be normal as the sample size increases.\n",
    "\n",
    "2. The mean of the sample means (the sampling distribution of the sample means) will be equal to the population mean.\n",
    "\n",
    "3. The standard deviation of the sample means (the standard error) will be equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "**Significance of the Central Limit Theorem:**\n",
    "\n",
    "The Central Limit Theorem is of great importance in statistics and data analysis for several reasons:\n",
    "\n",
    "1. **Approximation of the Normal Distribution:** It allows analysts to use the normal distribution as an approximation for the distribution of sample means, even when the original population is not normally distributed. This is significant because the properties of the normal distribution are well-understood and extensively used in statistical inference.\n",
    "\n",
    "2. **Statistical Inference:** It is the foundation for many statistical techniques, such as hypothesis testing and confidence interval estimation. When dealing with sample means from larger samples, the CLT simplifies statistical analysis.\n",
    "\n",
    "3. **Sample Size Independence:** The CLT suggests that the sample size, not the population size, is the critical factor in determining when the sampling distribution of the sample means becomes approximately normal. This means that the CLT applies to both large and small populations.\n",
    "\n",
    "4. **Generalizability:** The CLT is not restricted to specific population distributions, making it widely applicable to real-world scenarios. It allows analysts to work with samples from a wide range of data sources.\n",
    "\n",
    "5. **Quality Control:** In quality control and manufacturing, the CLT helps establish control limits and assess product quality by providing a basis for understanding the distribution of sample statistics.\n",
    "\n",
    "6. **Scientific Research:** The CLT is essential in scientific research when assessing the validity of hypotheses, conducting experiments, and drawing conclusions based on sample means.\n",
    "\n",
    "7. **Survey Sampling:** In survey research, the CLT guides the design of samples and the interpretation of results. It is used to make inferences about a population from a sample.\n",
    "\n",
    "In summary, the Central Limit Theorem is a fundamental concept that allows statisticians and researchers to make informed inferences about populations, regardless of the shape of the original distribution. It simplifies and enhances statistical analysis and plays a crucial role in various fields, from quality control to scientific research."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a90ab169-df45-4330-9342-cd3d68939c33",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df531847-1caa-4cbb-b78c-8def33a5a99e",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) assumes that data is randomly sampled, independent, comes from a population with a finite variance, and that the sample size is large enough. It underpins statistical inference by stating that the sample means become approximately normally distributed as sample size increases, allowing for the application of common statistical techniques to a wide range of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb094e4-68d1-4299-8756-e0a936b941ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
